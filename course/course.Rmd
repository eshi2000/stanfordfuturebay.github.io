---
title: "Shaping the Future of the Bay Area: Intro to Urban Data Analytics in R"
author: "Stanford Future Bay Initiative"
date: "Last updated: `r format(Sys.Date(), '%B %d, %Y')`"
output: 
  bookdown::gitbook:
    df_print: paged
    split_by: section
    config:
      toc:
        collapse: none
        scroll_highlight: yes
        before: |
          <li><a href="https://bay.stanford.edu">Stanford Future Bay Initiative</a></li>
        after: null
      toolbar:
        position: fixed
      edit : null
      download: null
      search: yes
      fontsettings:
        theme: white
        family: sans
        size: 2
      sharing:
        facebook: no
        github: no
        twitter: no
        linkedin: no
        weibo: no
        instapaper: no
        vk: no
        all: no
      info: no
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = F}
knitr::opts_chunk$set(warning = F, message = F)
```

# Introduction

The following is a data analytics curriculum specifically designed for the intro track of [Shaping the Future of the Bay Area](http://bay.stanford.edu/education), the flagship course of the Stanford Future Bay Initiative. Stanford students who enroll in the course will work through this material alongside lectures and discussions, and are expected to complete the assignments at the end of each chapter for a grade. Those students can then continue on to participate in practicum projects that make use of these technical skills.

This curriculum is also designed to be useful to a wider audience. Depending on interest, we may create platforms for the general public to engage with the instructors and each other. If you have any questions or comments, reach out to lead instructor Derek Ouyang at douyang1@stanford.edu. 

If you don’t have prior experience in R, this curriculum is designed to help you learn it from scratch. If you have some prior experience, you will likely be able to skim over anything that looks familiar and focus on new techniques. There are many other useful R educational resources online that we will occasionally refer to, and that may be just as useful if not more useful to help you learn R. The best place to start is [r.stanford.edu](r.stanford.edu).

In this introductory chapter, we will cover the following:

- Downloading all the relevant software that we recommend
- Navigating the RStudio interface, which is our preferred R development environment
- Navigating R Markdown files, which is our preferred R file format
- Pulling and Pushing GitHub repos, and publishing R Markdown reports to create web pages similar to the one you’re on
- Reading data into your R environment, particularly CSVs to start
- Saving files in various formats, and saving code progress generally
- Looping through operations using the classic for loop
- Exploring and manipulating data in basic ways, particularly with tidyverse functions
- Plotting data in simple charts using ggplot2
- Working with geospatial data using sf, tigris, mapview, and leaflet
- Loading Census data using censusapi

You can navigate through the chapters using the sidebar. 

## Software Setup

- Download the latest version of R [here](https://cran.r-project.org/).
- Download RStudio [here](https://www.rstudio.com/products/rstudio/download/).
- Create a GitHub account [here](https://github.com/join). When you publish your own code and Markdown reports, you’ll be doing it on your own GitHub account. 
- Download GitHub Desktop [here](https://desktop.github.com/). 

For those enrolled in the Stanford course: 

- Make sure you're set up fully on Slack. The #r-help channel is shared with the entire Stanford community and is the best place to ask for help on eccentric R problems you can’t seem to find a solution to when Googling. For questions specific to this course material, you will be invited to specific channels for each chapter/assignment. Note that in a Slack message you can insert code using the “Code” or "Code block" options, which are always preferable to just pasting code directly into your message. Otherwise, if your code is on GitHub, we’d recommend sharing a URL that links to the direct line of code you’re referring to, like https://github.com/stanfordfuturebay/stanfordfuturebay.github.io/blob/master/covid19/safegraph_normalization_function.R#L47.
- Download Cisco VPN [here](https://uit.stanford.edu/service/vpn). For certain R applications you might find it useful to connect to the Stanford VPN.

## RStudio Interface

*Note: In this section I’ll start to occasionally refer to keyboard shortcuts. As a PC user, I will always show PC shortcuts. Hopefully, for Mac users it will be relatively easy to figure out what the appropriate Mac version is. Apologies in advance for any inconvenience.*

Double check your RStudio version under `Help > About RStudio`, and your R version under `Tools > Global Options`. You will also always be able to check package versions under `Tools > Check for package updates`. When you experience errors, we'll want to be able to investigate version compatibility as a source of the error.

You can update individual/all packages using the Tools option noted previously at any time, but generally I wouldn’t necessarily recommend updating to the absolute latest version just because, since this can sometimes cause past scripts to no longer run. Just beware of this as a way to solve compatibility issues that seem to exist between two users.

RStudio generally has four “windows”:

- **Source**: Default top left. If you don’t already see this window, go ahead and open up a new .Rmd file at `File > New > R Markdown` and you’ll see some template code sitting in an “Untitled” document in the Source window (we’ll talk about how to read a .Rmd document soon). The Source generally will have multiple tabs of either code documents you’re editing or environment data you’re viewing. You generally spend most of your time working here. 
- **Console**: Default bottom left. This is where you actually “run” code. You can type lines of code directly into the console and run them, or you can execute lines of code from the Source window which basically “sends them” to the Console. 
- **Environment**, etc.: Default top right. As you execute code you’ll end up creating “data” (generally done with a line of code that has the form `data_variable_name <- functions`), and any data that’s been created will sit in the “Environment”, and you’ll see individual objects listed here. You’ll be able to refer to objects in the Environment as part of subsequent lines of code. To remove objects, you generally will type `rm(data_variable_name)` into the Console, or you can clear the whole Environment using the little broom icon. You rarely will use the other tabs in this window.
- **Files**, etc.: Default bottom right. This should basically look like a view into some folder on your computer. You’ll always have a “working directory” where your R code by default “looks for” objects to load from, or export outputs into. So generally you’ll want to view your working directory here. We’ll discuss this more soon. The other tabs in this window are useful, but generally they’ll automatically show up depending on specific code you execute, so we’ll talk about them later.

I personally prefer a different layout than the default. You can adjust layout under `View > Panes > Pane Layout`. I flip the Console and Environment windows. It’s also good to practice right away the shortcuts to temporarily zoom into one of these windows depending on what you’re doing: Try double-tapping `Ctrl+Shift+1`, `Ctrl+Shift+2`, `Ctrl+Shift+8`, or `Ctrl+Shift+9` to see what I mean. 

Typically the first thing I do when beginning to code is set the working directory for whatever I'm working on. In the Files window, navigate to your desired folder (usually the cloned GitHub repo where your code is located; more on that soon), then click the gear button `More > Set as working directory`. If you try this, you’ll see the written version of this step pop up in the Console, but I generally find it easier to set working directories using the user-friendly buttons.

Next, in the script window itself, the white gear wheel has an option to show chunk output "inline" or "in Console". By default it's "inline", but I almost always switch to "in Console". This is ultimately up to personal preference, but I like to always have code output show up in one place, the Console (or, if it’s a plot/map, in the File window). 

You can easily try out the Console by typing random math equations and clicking enter. Conversely, note that in line 19 of your standard .Rmd template you should see `summary(cars)`. If you put your cursor anywhere on that line of text and click `Ctrl+Enter`, you should see that the Console essentially copied that one command and executed it. `cars` happens to be a default data frame built into R, and `summary()` tells you some general information about the data frame. You can now also try typing `summary(cars)` directly into the Console, and write a new line of code in line 19 like `1+1` and execute that using `Ctrl+Enter` (make sure you write this between the pair of three backticks -- we’ll explain soon -- and that again your cursor is somewhere on the line you want to execute), to demonstrate to yourself that it’s all one and the same to the Console.

Some of the most common commands I’d run directly in the console are:

- `View(data_variable_name)` to view data frame that’s in the Environment
- `colnames(data_variable_name)` to view the field names of the data frame
- `mapview(data_variable_name)` to quickly view a mappable object (you’ll need to have loaded the relevant library to do this, which we’ll explain later)

Otherwise, I’m generally running code “inline” by putting the blinking typing cursor on any part of a line and doing `Ctrl+Enter`. If you only want to run part of a line (especially `%>%` pipelines, explained later), then you highlight a specific self-contained section before typing `Ctrl+Enter`. `Ctrl+Shift+Enter` will run the entire chunk of code (which is between the pairs of three backticks). 

Note that so far we’ve introduced one “function”, `summary()`. It’s simplest to think of these as “machines” that create some output based on some input(s) you feed it. You put the inputs inside the parentheses. Sometimes a function doesn’t need any inputs (we’ll encounter one soon); sometimes it needs multiple inputs, which are separated by commas. When there are multiple inputs, the function always has a “schema” that guides you in the correct order of inputs, and there’s always a way to explicitly tell the function what input you’re providing to fill what argument. You can generally see this explained if you search “r somefunction” on Google, or by typing `?somefunction` in the Console to get a quick tutorial in Files window (though this isn't always as useful as Googling the same thing). If you try `?summary`, you’ll see a list of arguments, and you’ll notice that `cars` was an input we provided to fill the first default argument, “object”.

Other miscellaneous notes at this point:

- Observe what happens when you double click and triple click on code. Generally you get an entire “word” or “line”, which can help speed up certain kinds of copy/paste operations.
- Similarly, observe what happens when you hold `Ctrl`, `Shift`, `Ctrl+Shift`, or `Alt` and move up/down/left/right through code. All of these combinations can be handy to speed up different kinds of tasks.
- I use `Ctrl+PgUp/PgDn` for fast navigation through the document. 
- Comment out and uncomment lines in Source documents by putting your cursor anywhere on the line and typing `Ctrl+Shift+C`.

Generally keep in mind that most things you want to do in R and RStudio are "designed" to be easy, but the knowledge can’t easily be conveyed to you (beyond guided tutorials like these), so you often have to do the Googling yourself to seek out those efficiency gains. Don't assume that something can't be done, leaving you stuck doing something that seems difficult to you; assume somebody has solved the problem somewhere! This is of course also very true when it comes to the code itself.

If you need a deeper explanation of these and many other fundamental concepts we’ll skip over in this course, start [here](https://r4ds.had.co.nz/introduction.html#prerequisites), then do more Googling.

## R Markdown Files

The two most common types of R code documents are .R or .Rmd files. First, keep in mind that in either case they’re really just text files, but fed into R development environments like RStudio, they end up “doing R things”. A normal .R file is literally just code top to bottom to execute. An .Rmd file intersperses code with space for non-code commentary (in a language called markdown), which is especially useful for creating web documents just like the one you’re viewing right now. Since we want to teach you how to create such public-facing documents for a wide variety of uses, and because it’s often convenient anyway to intersperse code with explanatory text, we’re going to use .Rmd files as the preferred format. But that means we have a few different formatting details to explain that, from the onset, may look strange.

You should have a new .Rmd file open that has a standard template. Usually, when I am starting a new .Rmd, I immediately erase this template and start to copy/paste script from other existing .Rmd files, but for now it’s useful to review this “scaffolding” to learn.

At the top, between two `---` lines, is something called a YAML header (I leave you to Google to your heart's desire for more insight, and just give you the basic orientation here), which feeds high-level information to what’s called a "knitting" operation (explained soon), which takes your document and does the "web development" (or conversion to other end formats like PDF) for you. For example, the YAML header is where you can type a preset table of contents parameter so you never have to bother with designing a table of contents in HTML (this extensive multi-page website, with the left sidebar navigation, is also structured using some simple YAML commands). Just know there are many cool parameters you can learn to use up there to make your web page even cooler, which you can look up when appropriate. Generally, besides many nifty HTML tricks, there are two fundamental things you should always do in the YAML:

- Give your .Rmd file a title, which will render at the top of the web document. This doesn’t have to be the same as the file name you give to your .Rmd file.
- You should specify your date based on when you last edited this code. As an advanced technique, you can type the following: `` `r '\x60r format(Sys.Date(), "%B %d, %Y")\x60'` ``. This will automatically update the date based on when you “knit”. There are three important concepts here. First, if you are not inside of a “chunk”, which we’ll get to soon, then generally you can’t execute code. But if you do a pair of backticks, and include “r” right after the first backtick, then it’s like you’ve created a “mini chunk” that lets you run one line of code (as if you were typing it directly into the Console). So what you’ve put right into the YAML is the text output of the following code: `format(Sys.Date(), '%B %d, %Y')`, which you are free to try typing directly into the Console. Now this code itself is a function within a function. `Sys.Date()` is a standard function in base R (which means you have access to it anytime) which does exactly what you think it does; try it directly in the Console on its own. Nothing is required between the parentheses for certain self-evident functions like this. Finally, `format()` can do a lot of generally useful formatting things depending on what you feed in as parameters (it’ll do nothing on its own). When `format()` is given a date object, which is what `Sys.Date()` produces, as its first parameter, followed by a string in which you specify how you’d like to format the date, then it can convert something like “2020-09-14” into “September 14, 2020”. The exact schema itself is something you have to find guidance on; try Googling “r date format” and typing `?format` in the Console.

Now we’ll explain chunks which are a special formatting in .Rmd files to contain code you want to execute. Below I'm copying the first chunk you get in the template. A chunk is created by a pair of three backticks, and a bracketed set of parameters right after the first pair. Note that you can quickly create a chunk using `Ctrl+Alt+I`, one of the most common shortcuts I use.

```{r}
knitr::opts_chunk$set(echo = TRUE)
```

Note that on this web page, you don’t see the pair of three backticks, but if you were to view the .Rmd file that created this webpage, you’d see the backticks and bracketed parameters. So one of the nice features of an .Rmd file is that you can publish documents with chunks nicely rendered to display code, and if there are outputs to the code (which these don’t have), you can easily choose to display them right below the chunk.

I’ll now show a second chunk that has the same effect but a different formatting choice:

```{r}
library(knitr)
opts_chunk$set(echo = T)
```

The first chunk has one line of code while the second has 2 lines. The first example is basically a shortcut of the second which is the more general approach. `knitr` is what’s called a “package”, and packages contain functions; in this case, `opts_chunk()` is a function of `knitr` (note that this function has sub-functions via a \$ sign which is rare). If you have used `library()` to load a package, then you don’t need to put `knitr::` before the function call (the only situation in which this might be needed is if two loaded packages both have a function of the same name, in which case you need to specify which one you’re using; you’ll see me do this for `dplyr::select()`). Generally, you’ll load a bunch of functions with `library()` calls in your first chunk, which I’ll demonstrate soon.

In this case, `opts_chunk$set()` does something generally important for .Rmd files and relates to “knitting”. Its functionality is also something built into the structure of .Rmd files. I’ll now show the same chunk above, but with the full formatting that you would see in the .Rmd file:

````markdown
`r ''````{r}
library(knitr)
opts_chunk$set(echo = T)
```
````

I have to do some extra-special formatting of my own .Rmd file to get the pairs of triple backticks to show on this page, because the whole point of .Rmd files is that it converts that kind of information into backend information to then render web content. But it’s important to show you what the .Rmd formatting looks like.

For a chunk to be a chunk, you need the pairs of triple backticks and you need the bracket with an “r”. But you can add some parameters right after the “r” which affect that specific chunk. And these include the parameters you can feed into `opts_chunk$set()`; for example, you could add `, echo = T` after the “r” in the chunk above. The difference is that putting these parameters in the brackets affects only the one chunk, while `opts_chunk$set()` sets defaults for all subsequent chunks. Here are the most common parameters you would likely want to set:

- `echo = F` (in R generally you can type `T/F` or `TRUE/FALSE` for boolean logic) shows the code in a gray box when you render into a web page. This is the default case (I’m actually not sure why the template has it the way it is), so consider this parameter only useful if you wanted to set `echo = F` (say you’re creating a report in which the reader wouldn’t care about the code and only wants to see output graphs and maps, which would still show).
- `warning = F` and `message = F` prevent a lot of annoying warning messages from showing up in the web page, that you sometimes see in the RStudio console depending on what the code is doing. Generally these parameters are a good idea to set in `opts_chunk$set()` which applies them to all chunks, so as to clean up your web documents.
- `include = F` executes code in the background but does not show the code itself on the web page.
- `eval = F` prevents the code from being evaluated, but the code is still visible on the web page. Sometimes you’ll have some chunk that takes hours to run, and you don’t want to have to run it again when you knit, so you’ll end up saving the output of that long process as a file in your working directory and following up the first chunk with a second smaller chunk that just loads the completed file into your Environment. In this case, you might decide to show the first chunk on a web page but set it as `eval=F`, then hide the second chunk with `include = F`, but it is the one that actually retrieves the relevant output to continue using in the rest of your script.

As you can see, most of these details basically have to do with how the resultant web page looks, and don’t have much to do with the code itself, but it’s useful to understand these parameters now and get into the practice of having something like the following always as your first chunk (feel free to copy and paste this into your own .Rmd file):

````markdown
`r ''````{r setup, include = F}
knitr::opts_chunk$set(warning = F, message = F)
```
````

Note that the chunk itself won’t display in a web page because of `include = F`, but it will evaluate, and it specifically sets `warning = F` and `message = F` to apply to all future chunks. You can still apply other parameters individually to subsequent chunks as desired. Note also that I went back to using `knitr::` since there’s basically no other need for `knitr` package functions in most cases. Lastly, note the label `setup` written after `r` but before a comma. The word you put right after `r` basically just names the chunk. This basically helps with quick navigation using a small drop-down menu you can find on the bottom of the Source window. There’s also value in doing this if you want to add automatically numbered captions to your plots, which won’t be taught in this curriculum. Otherwise I usually don't name my chunks because I find it easier and more user-friendly to organize my document using hashtag headers in the non-chunk areas, as you can see done in your template. `Ctrl+Shift+O` opens a Google Doc style outline on the right tab which is useful for navigating your document.

After that first setup chunk, next you would usually have a "loading libraries" chunk. Mine typically look something like this (note I am no longer forcing the triple backticks portion to show, so you’ll just see the code within the chunk):

```{r}
library(tidyverse)
library(plotly)
library(sf)
library(tigris)
library(mapview)
library(leaflet)
library(censusapi)

Sys.setenv(CENSUS_KEY="c8aa67e4086b4b5ce3a8717f59faa9a28f611dab")
```

All the `library()` calls are loading packages that you know you need to run the code in the rest of the script. Generally you’ll have some idea of the essential ones you always use, but as you are working on a novel problem, you may discover a new special package you want to use, and you’d scroll up and add it to this chunk. The list above happens to be the "essential" packages I’ll cover later in this chapter.

Usually after the `library()` calls, you would set other kinds of environmental “settings'' that are relevant to specific code you’ll use later on; setting them here merely provides the benefit of having all these settings in one place, but they could go anywhere as long as they are executed before the relevant code they affect. Here I am calling `Sys.setenv()` which relates to the `censusapi` package, which I’ll explain near the end of the chapter. Other common settings you might put in this chunk:

- If you are sharing code between users who might have different file paths, then generally it’s a good idea to create a variable like `path <- "G:/Shared drives/SFBI-Restricted/"`. This holds a string of text which will then be prefixed to other text later on, say to create a full file path to grab some CSV that is in that folder. This happens to be the right file path for me on a PC, but if somebody else has access to the same drive but is a Mac user, they might need to replace this with `path <- "/Volumes/GoogleDrive/Shared drives/SFBI-Restricted/"`. So then it’s easy for somebody to make this adjustment once in this line of this early chunk. (Note that often code will sit in cloned GitHub repos that you would have set your working directory to manually, in which case any smaller and simpler files you load in from the same repo don’t need an absolute file path like this; absolute file paths tend to be for grabbing large or sensitive data from a secure server; GitHub repos will be explained more in the next section.)
- A few packages will have special options you need to set, but they’ll generally be options you can set inside of `options()`, delineated by commas. We’ll encounter some of these later in the curriculum.

Of course, most of the “R” action happens in the code chunks themselves, which we haven’t yet dived deeply into. The writing that's happening in non-chunk areas is in "markdown" language, which you can think of as an easy language for displaying text, and you can always easily Google for the right markdown syntax to do things like **bold**, *italics*, tables, etc (don’t feel like you need to memorize if you can Google). 

Lastly, note there's a "Knit" button next to the white gear, and that's what you ultimately click to export a HTML file. If successful, after a few seconds you’ll see a `filename.html` in your working directory (likely you’ll see this right away in your File window since you’re typically looking at your working directory), and by default RStudio will open up a window that gives you a preview of what the HTML file would look like as a web page. You are welcome to try it now, and notice that your simple .Rmd file doesn’t really do much interesting in terms of code, but you can already practice all the markdown formatting you want.

If you need a deeper explanation of these and many other fundamental R markdown concepts we’ll skip over in this course, start [here](https://r4ds.had.co.nz/r-markdown.html), then do more Googling.

## GitHub

You can learn how to code in R without using GitHub, but GitHub is the standard platform for sharing your code with teammates and with the general public. If you aren’t already familiar with GitHub, basically, GitHub is like Google Drive but you have to actively “fetch/pull” to get updates from the cloud downloaded to your machine, and “commit/push” to send your changes to overwrite what’s in the cloud. The user-friendly way to do this is with GitHub Desktop, which you should have installed; generally you’d have GitHub Desktop open as its own window while you’re working in RStudio. 

GitHub Desktop doesn’t replace lots of activity you’d still do on GitHub.com, where you should have made a personal account. On GitHub.com you create repos which are like Drive folders, and which can have collaborators who have view/edit permissions. GitHub keeps track of changes for all files in a repo, kind of like version history on Google Docs. This version control is really only important when you have a lot of people working together on the same repo, which you won’t necessarily experience in this curriculum, but it’s useful to start practicing good habits on GitHub.

If you haven’t already, I’d recommend doing the [tutorial](https://guides.github.com/activities/hello-world/) on GitHub.com to understand the basic concepts and terminology, and then you can review the GitHub Desktop [tutorial](https://docs.github.com/en/desktop/installing-and-configuring-github-desktop/creating-your-first-repository-using-github-desktop). The general workflow for starting a new coding project would be something like this:

1. Create a repo on GitHub.com.
2. Clone it on GitHub Desktop (there’s a button to initiate this from online, or within GitHub Desktop, if you’ve linked to your account, you can do `File > Clone Repository` and then search for it by name). This makes a copy of the repo on your personal machine, likely in an automatically created “GitHub” folder.
3. In RStudio, set your working directory to this empty folder.
4. Create a new .Rmd file, save it into the working directory, which would be the first observed “change” in your cloned repo.
5. On GitHub Desktop, you’ll see those changes detected. Commit those changes, which usually involves writing a summary in the bottom left of the window, clicking `Commit to master`, then clicking the button in the top tab that switches its name from `Fetch origin` to `Pull origin` to `Push origin` depending on what’s going on. If this is your first time “pushing”, it will say `Publish branch`.

If you’re working alone, you will just continue to make edits to the repo, and whenever you want to push, you repeat step 5. If you’re working in a team, and others may be editing the same repo, then always `Fetch origin` and `Pull origin` before you get started on anything in RStudio, to make sure you’re working off the latest version someone else might have edited, and then `Commit to master` and `Push origin` regularly and especially when you’re done working on something, so others can access your updated content. You’re trying to avoid creating parallel universes of code. If you want to play it safe, then you can always just create your own `something_yourname.Rmd` copies of code, but your team ultimately would need to decide how to merge various branches of code development back together. This becomes mainly a question of project management and team coordination on Slack. 

So far, all these GitHub practices probably feel like busywork, especially given there’s not much to show off or collaborate on yet in terms of actual code. My main reason for introducing this now is to now explain a more advanced use case of GitHub, called GitHub Pages, which is great for helping you actually publish your knitted HTML files to the web. Generally, if you have an HTML file, there are a number of ways to host that content online, but GitHub Pages is a streamlined option if you’re already using GitHub. Basically, follow the simple [instructions](https://pages.github.com/), and you’ll create a specialized repo called `username.github.io` that GitHub treats like the “host” for web content, so if you push an HTML file to it, then within a minute or so, you can see the content at the URL `username.github.io/filename.html`, and importantly, send this URL to others for them to see your content. So then the publishing workflow would be something like this:

1. Make sure you’ve created the special `username.github.io` repo and have cloned it to your local machine.
2. Work in RStudio on a .Rmd file that you ultimately want to showcase online.
3. When ready, click `Knit` and generate an HTML file in your working directory. Preview it and make sure it looks the way you want.
4. Copy or move the HTML file from the working directory (which would be a clone of a repo from your GitHub account) to the `username.github.io` folder on your machine (which is also a clone of a repo from your GitHub account, but is the “special” web hosting repo).
5. In GitHub Desktop, you’ll see that changes have been detected in both the original project repo and the special web hosting repo. Commit changes to both, and push both. 
6. In a minute or so, you can try loading `username.github.io/filename` on your web browser, and you should see the same thing you had previewed.

Note that when you start working with more complex interactive maps and charts, you might start to have other support files/folders that get generated by the “knitting” function that you have to copy/paste over along with the HTML file. And that’s basically all there is to it. Practice this as much as you want to start to create your own URLs. You can have as many as you want accessible through this domain, but it’ll take extra web development knowledge to do fancier things like format `username.github.io` itself to be a “home page” with a directory to all the other web material. Your general use case will be just sending individual URLs like `username.github.io/filename` to people on Slack or email. Those completing the assignments at the end of each chapter will be asked to “submit” their work as web pages using this exact method.

OK, now we’ll finally get into R coding. Before moving on, go ahead and set up a cloned GitHub repo, with any name you’d like, save your current .Rmd example file in that folder on your local machine, and set that folder as your “working directory” in RStudio.

## Reading and saving files

Generally you will be loading data into RStudio from some source, making it more useful or generating insights from it in some way, and then exporting that data out in raw or visualized form. Here are the common ways you’d read data into RStudio:

1. Find a link online that lets you directly download a data file (e.g. CSV), and use that to directly load data into your Environment. If you find such a link or API, and if it’s stably maintained on the webpage, this is the easiest method.
2. If for whatever reason it’s not easy to use the URL as the file path, but you can download the data onto your personal machine or a server, then read the data using the local file path instead. This is also very easy and often a great solution for working in teams that share the same server, but assumes you have set up such a file storage solution, and you might need to worry about changing file paths for different users, as we’ve discussed.
3. A variety of packages have functions designed to essentially do Option 1 but with many convenient wrappers around the process, so that instead of having to find URLs or APIs and work with them yourself, you can interact with function parameters and get various pre-processed results. We’ll experience this later in this chapter.
4. A variation on downloading datasets from online is scraping content directly from web pages, which will be the subject of a later chapter.

In this section, we’ll demonstrate Options 1 and 2. 

In either case, functions from the `tidyverse` package will come in handy. The [tidyverse](https://www.tidyverse.org/) is a popular collection of packages that all “share an underlying design philosophy, grammar, and data structures”. It’s creator, Hadley Wickham, was a contributor to the [Data Challenge Lab course](https://dcl-docs.stanford.edu/home/) that used to be taught at Stanford (and which, by the way, has a more comprehensive online curriculum that you’re encouraged to also use as a resource to learn R). Basically, we, along with many others believe that features of `tidyverse` are a deeply intuitive way to learn and use R, and through this curriculum we will essentially be attempting to convince you of that too.

We’ll dive much more deeply into `tidyverse` later, but for now, we’ll focus on the functions within its packages that are designed to read data. `readr` is the main one.

In an earlier chunk, I’ve already loaded `library(tidyverse)`. `tidyverse` uniquely brings in multiple [core packages](https://www.tidyverse.org/packages/) when you call it with `library()`, but in principle you could load `library(readr)` on its own. 

The `tidyverse` packages have great documentation, so it’s worth generally reviewing what information is available for [readr](https://readr.tidyverse.org/). Since CSVs are one of the most common types of data format you’d find online, `read_csv()` is the most common function you’d use, along with its exporting equivalent, `write_csv()`. 

For our example, let’s look at a large health dataset provided by the Centers for Disease Control and Prevention (CDC) called [500 Cities](https://chronicdata.cdc.gov/500-Cities/500-Cities-Local-Data-for-Better-Health-2019-relea/6vp6-wxuq). Without going into the full background of this data project which you can read about, I’ll simply note that this dataset provides estimates of many health outcomes that typically are difficult to find public data on at the census tract level (more on geographies soon) in the 500 largest U.S. cities. The dataset is fairly large so is also a good test of your personal machine and its ability to handle the kinds of datasets you would expect to be handling in R. On the CDC website, if you were looking for how to grab the data directly from R, you’d be looking for a direct link to .csv data, which requires manual searching. In this case, this can be found in the “Export” button, and copying the link address yields `https://chronicdata.cdc.gov/api/views/6vp6-wxuq/rows.csv?accessType=DOWNLOAD`. `read_csv()` has a straightforward schema, as shown below:

```{r, eval = F}
health_full <- read_csv("https://chronicdata.cdc.gov/api/views/6vp6-wxuq/rows.csv?accessType=DOWNLOAD")
```

`<-` is used to assign the result of functions to an Environment variable. You can supply a variable name of your choice on the left side. There are some general rules around this, like having no spaces, not leading with a number, and not using certain special characters. You should also develop the habit of using understandable variable names while keeping them relatively short.

Running the line above may take a minute or more to load. You’ll notice a stop sign shows up in the Console, which lets you know that something is processing. When it’s complete, you’ll see a `>` show up again in the Console, and you’ll see the newly created variable in your Environment. You can click on it (or type `View(health_data)`) which will create a new tab in the Source window to view tabular data. As noted previously, `colnames(health_data)` in the Console quickly shows the names of the column headers (which matches the data dictionary you can find on the CDC site). 

Reading files can introduce lots of unique challenges, so part of getting good at R is learning how to troubleshoot the unexpected problems you’ll face when interfacing with web pages and different file types. We’ll encounter some more complicated situations throughout this curriculum and revisit advanced reading methods as appropriate.

We’ll be able to manipulate this data in a variety of ways, and generally with such large datasets you’d be interested in filtering to just the data you need, saving that locally, and then removing the larger original file. I’ll go ahead and demonstrate `filter()` which is from the `dplyr` package in `tidyverse` (more `dplyr` functions will be showcased soon):

```{r, eval = F}
health_ca <- filter(health_full, StateAbbr == "CA")
```

`filter()` takes as its first parameter some existing data object, and as its second parameter a logical condition. Here I’m referencing an existing field name, `StateAbbr`, which I know is spelled that way because I’ve reviewed the data structure, and I’m filtering to only rows of `health_full` that have “CA” in the `StateAbbr` field. The result goes from 800K to 150K rows. For Bay Area work we could further filter to find just the cities in the Bay Area, but for now we’ll go ahead and move on to other examples. 

Now let’s try an example that uses a local file path. PG&E is the local energy utility for the Bay Area, and it provides some ZIP code level data to the public [online](https://pge-energydatarequest.com/public_datasets). This site would be a good example of Option 1, except it has an extra pop-up window that shows up asking for the user to provide some info and fill out some boxes which means we can’t do exactly what we did in the last example (there would be a more involved approach akin to Option 4’s web scraping). But for our purposes, this is a good opportunity to try downloading data directly to your local machine. Go ahead and download 2019 electricity usage for four quarters, and make sure to unzip the CSV contents of the zip folders directly into your “working directory”, which you should have created at the end of the last section. You should see these CSVs immediately in your Files window.

Since we are using the working directory, then you can use relative file paths as follows:

```{r, eval = F}
pge_19_q1_elec <- read_csv("PGE_2019_Q1_ElectricUsageByZip.csv")
```

No additional file path information is required; RStudio will by default look inside the working directory for a "PGE_2019_Q1_ElectricUsageByZip.csv" unless you specify otherwise. This means it’s generally the easiest to put input data as well as output contents directly in the working directory, but since this is likely also a cloned repo, you will have constraints on file size if you are syncing to GitHub (generally 100MB per file). So as you start working with bigger files, then generally you’d be interfacing instead with a server location (e.g. Google Drive File Stream) and providing a longer file path.

Now let’s practice saving some outputs. If you wanted to create a CSV, then `write_csv()` is your best bet. Here’s what it would look like to save your California-filtered version of the CDC dataset:

```{r, eval = F}
write_csv(health_ca, "health_ca.csv")
```

Note that in this case, no `<-` is needed. `write_csv()` requires the data object you’re interested in, and a file path destination, which in this case we provided as a relative file path into the working directory (we could have supplied any name for this CSV). This should be ~40MB.

If you don’t need the output to be a CSV for reading into Excel or Google Sheets, and just want to save an output that can be loaded back into R in the future, then the best choice is R’s own data format, .rds. RDS files are more compact than CSVs, and you can hold any kind of data in .rds, as long as it’s “one” data object. `saveRDS()` can be used very similarly to `write_csv()`:

```{r, eval = F}
saveRDS(health_ca, "health_ca.rds")
```

Notice how the .rds file is a tenth the size of the CSV, even though it holds the same information. So if you’re trying to conserve storage space and allow for quick saving/loading, RDS files are the way to go.

Reading RDS files, by the way, looks like this:

```{r, eval = F}
health_ca <- readRDS("health_ca.rds")
```

In this case, you’ll just be overwriting the existing `health_ca` data object in your Environment. Note that, like `read_csv()`, you get to pick whatever name you want on the left side for your variable.

There are of course many other possible formats you can output data which we’ll encounter as we go. The last point I’ll make in this section is that a set of Environment variables can be saved together in an .rdata or .rds file, which you can think of as similar to .rds but able to hold more than one object at a time. For example, you could run:

```{r, eval = F}
save(health_ca, pge_19_q1_elec, file = "working_datasets.rda")
load(“working_datasets.rda”)
```

Note:

- The relevant function is now `save()`.
- You could list as many Environment variables as you’d like, separated by commas.
- The argument `file = ` needs to be explicitly spelled out here. In fact this could have spelled out for `saveRDS()` but was unnecessary then, whereas here it’s necessary to avoid misinterpretation by the function, given that there are many other kinds of arguments that can be fed to `save()`.
- To read in an .rda file, you need to use `load()`. One key difference between `readRDS()` and `load()` is that you can’t specify a variable name, since there might be multiple variables incoming.

If you just wanted to save the entire Environment, then you could do:

```{r, eval = F}
# SAVE POINT
save.image("progress1.rda")
load(“progress1.rda”)
```

I like using this like a “save” button in a video game, designed as specific checkpoints throughout a long script. If you don’t want to lose the contents of “progress1.rda”, you’d generally leave the `save.image()` line commented out using `Ctrl+Shift+C`, and only un-comment it if you want to change the contents of the .rda file. 

## Loops

In progress

## Manipulating data

In progress

http://adv-r.had.co.nz/Style.html

https://www.gastonsanchez.com/r4strings/character-sets.html

## Plots

In progress

## Geospatial data

In progress

https://opendata.mtc.ca.gov/datasets/-san-francisco-bay-region-2010-census-block-groups-clipped?geometry=-122.754%2C37.677%2C-122.024%2C37.867

## Census data

In progress

# Populations

In progress

## Spatial joins

In progress

## Equity analysis

In progress

